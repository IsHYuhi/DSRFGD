{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import random\n",
    "from typing import Optional, Tuple, List\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision.transforms as TF\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Here, please refer to and copy this snippet https://github.com/naoto0804/SynShadow/issues/6#issuecomment-892511226\n",
    "\n",
    "@article{inoue2021learning,\n",
    "  title={{Learning from Synthetic Shadows for Shadow Detection and Removal}},\n",
    "  author={Inoue, Naoto and Yamasaki, Toshihiko},\n",
    "  journal={IEEE Transactions on Circuits and Systems for Video Technology},\n",
    "  year={2021},\n",
    "  volume={31},\n",
    "  number={11},\n",
    "  pages={4187-4197},\n",
    "  doi={10.1109/TCSVT.2020.3047977}\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(shadow_free: torch.Tensor, mask: torch.Tensor) -> torch.Tensor:\n",
    "    assert shadow_free.ndim == 3 and mask.ndim == 3\n",
    "    assert shadow_free.size()[1:] == mask.size()[1:]\n",
    "    assert 0.0 <= shadow_free.min() and shadow_free.max() <= 1.0\n",
    "    assert 0.0 <= mask.min() and mask.max() <= 1.0\n",
    "    darker_image = darken(shadow_free, x_turb_sigma=0.0)\n",
    "    # to randomize shadows color\n",
    "    # darker_image = darken(shadow_free, intercepts_mode=\"affine_unsync\")\n",
    "    shadow = mask * darker_image\n",
    "    shadow += (1 - mask) * shadow_free\n",
    "    return shadow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42) -> None:\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(img: np.ndarray) -> np.ndarray:\n",
    "    mask = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) if img.ndim == 3 else img\n",
    "    mask = np.where(mask == 255, 0, 255 - mask)\n",
    "    mask = mask[:, :, np.newaxis] / 255\n",
    "    return mask\n",
    "\n",
    "\n",
    "def syn_picture_text(\n",
    "    pic: np.ndarray, text: np.ndarray, text_mask: np.ndarray\n",
    ") -> np.ndarray:\n",
    "    pic_text = np.array(((1 - text_mask) * pic + text_mask * text), dtype=np.uint8)\n",
    "    return pic_text\n",
    "\n",
    "\n",
    "def syn_texture(\n",
    "    img: np.ndarray,\n",
    "    texture: np.ndarray,\n",
    "    text_mask: np.ndarray,\n",
    "    seg_mask: np.ndarray,\n",
    "    alpha: float = 0.7,\n",
    "    beta: float = 0.3,\n",
    "    gamma: float = 0.0,\n",
    "    color_weight: Optional[Tuple[float, float]] = None,\n",
    ") -> np.float:\n",
    "    if color_weight is None:\n",
    "        dst = cv2.addWeighted(img, alpha, texture, beta, gamma)\n",
    "    else:\n",
    "        dst_back = cv2.addWeighted(img, alpha, texture, beta, gamma)\n",
    "        dst_text = cv2.addWeighted(\n",
    "            img, color_weight[0], texture, color_weight[1], gamma\n",
    "        )\n",
    "        dst = np.array(\n",
    "            (\n",
    "                (1 - (text_mask + seg_mask)) * dst_back\n",
    "                + (text_mask + seg_mask) * dst_text\n",
    "            ),\n",
    "            dtype=np.uint8,\n",
    "        )\n",
    "    return dst\n",
    "\n",
    "\n",
    "def syn_background(\n",
    "    img: np.ndarray,\n",
    "    background: np.ndarray,\n",
    "    text_mask: np.ndarray,\n",
    "    seg_mask: np.ndarray,\n",
    "    ratio: float = 1.1,\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    h, w, c = img.shape\n",
    "    if h * 3 / w < 4:\n",
    "        bw = w\n",
    "        bh = w * 4 / 3\n",
    "    else:\n",
    "        bw = h * 3 / 4\n",
    "        bh = h\n",
    "    background = cv2.resize(\n",
    "        background, (int(bw * ratio), int(bh * ratio)), interpolation=cv2.INTER_CUBIC\n",
    "    )\n",
    "    bh, bw, c = background.shape\n",
    "    on_back = background.copy()\n",
    "    dh = 0 if bh == h else np.random.randint(0, bh - h + 1)\n",
    "    dw = 0 if bw == w else np.random.randint(0, bw - w + 1)\n",
    "    on_back[dh : h + dh, dw : w + dw] = img\n",
    "\n",
    "    on_back_text = np.zeros_like(on_back[:, :, 0:1]).astype(np.float64)\n",
    "    on_back_text[dh : h + dh, dw : w + dw] = text_mask\n",
    "\n",
    "    on_back_seg = np.zeros_like(on_back[:, :, 0:1]).astype(np.float64)\n",
    "    on_back_seg[dh : h + dh, dw : w + dw] = seg_mask\n",
    "\n",
    "    paper_mask = np.zeros_like(on_back[:, :, 0:1]).astype(np.float64)\n",
    "    paper_mask[dh : h + dh, dw : w + dw] = 1.0\n",
    "\n",
    "    return on_back, on_back_text, on_back_seg, paper_mask\n",
    "\n",
    "\n",
    "def syn_shadow(img: np.ndarray, shadow: np.ndarray, scale: float = 0.5) -> np.ndarray:\n",
    "    t = TF.ToTensor()\n",
    "    img_tensor = t(img)\n",
    "    shadow_tensor = t(shadow)\n",
    "    shadowed = generate(img_tensor, shadow_tensor * scale)\n",
    "    shadowed = (shadowed.detach().cpu().numpy().transpose(1, 2, 0) * 255).astype(\n",
    "        np.uint8\n",
    "    )\n",
    "    return shadowed\n",
    "\n",
    "\n",
    "def perspective_trans(\n",
    "    img: np.ndarray,\n",
    "    shadowed_img: np.ndarray,\n",
    "    text_mask: np.ndarray,\n",
    "    seg_mask: np.ndarray,\n",
    "    paper_mask: np.ndarray,\n",
    "    scale: float = 1.05,\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    scale = scale - 1\n",
    "    h, w, c = img.shape\n",
    "    p_original = np.float32([[0, 0], [w, 0], [0, h], [w, h]])\n",
    "    dw = [np.random.randint(0, int(w * scale)) for _ in range(4)]\n",
    "    dh = [np.random.randint(0, int(h * scale)) for _ in range(4)]\n",
    "    p_trans = np.float32(\n",
    "        [\n",
    "            [0 - dw[0], 0 - dh[0]],\n",
    "            [w + dw[1], 0 - dh[1]],\n",
    "            [0 - dw[2], h + dh[2]],\n",
    "            [w + dw[3], h + dh[3]],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    M = cv2.getPerspectiveTransform(p_original, p_trans)\n",
    "    dst = cv2.cvtColor(img, cv2.COLOR_BGR2BGRA)\n",
    "    dst_shadowed = cv2.cvtColor(shadowed_img, cv2.COLOR_BGR2BGRA)\n",
    "\n",
    "    i_trans = cv2.warpPerspective(dst, M, (w, h))\n",
    "    i_trans_shadowed = cv2.warpPerspective(dst_shadowed, M, (w, h))\n",
    "    text_mask = cv2.warpPerspective(text_mask, M, (w, h))\n",
    "    seg_mask = cv2.warpPerspective(seg_mask, M, (w, h))\n",
    "    paper_mask = cv2.warpPerspective(paper_mask, M, (w, h))\n",
    "\n",
    "    return i_trans, i_trans_shadowed, text_mask, seg_mask, paper_mask\n",
    "\n",
    "\n",
    "def get_average_color(x):\n",
    "    b, g, r = x[:, 0], x[:, 1], x[:, 2]\n",
    "\n",
    "    return np.array([np.mean(b), np.mean(g), np.mean(r)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "\n",
    "root_path = \"../dataset/FSDSRD\"\n",
    "dirs = [\"img\", \"gt\", \"text_mask\", \"figure_mask\", \"seg_mask\", \"shadow\", \"avg_color\"]\n",
    "for dir in dirs:\n",
    "    if not os.path.exists(os.path.join(root_path, dir)):\n",
    "        os.mkdir(os.path.join(root_path, dir))\n",
    "\n",
    "shadows = glob.glob(\"../data/shadows/*\")\n",
    "textures = glob.glob(\"../data/textures/*\")\n",
    "backgrounds = glob.glob(\"../data/backgrounds/*\")\n",
    "text_paths = glob.glob(\"../data/EN/*/orig_texts/*\")\n",
    "\n",
    "nums = len(text_paths)\n",
    "h = 1200\n",
    "w = 900\n",
    "c = 3\n",
    "\n",
    "df = pd.DataFrame()\n",
    "img_paths = []\n",
    "gt_paths = []\n",
    "shadow_mask_paths = []\n",
    "text_mask_paths = []\n",
    "figure_mask_paths = []\n",
    "\n",
    "background_colors: List = [[], [], []]\n",
    "\n",
    "k = 0\n",
    "for i in tqdm(range(nums)):\n",
    "    path = text_paths[i]\n",
    "    picture = cv2.imread(path.replace(\"orig_texts\", \"orig_backgrounds\"))\n",
    "    picture = cv2.cvtColor(picture, cv2.COLOR_BGR2RGB)\n",
    "    text = cv2.imread(path)\n",
    "\n",
    "    for j in range(1):\n",
    "        num = str(k).zfill(5)\n",
    "        texture = cv2.imread(textures[np.random.randint(0, len(textures))])\n",
    "        texture = cv2.resize(texture, (w, h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        text = cv2.resize(text, (w, h), interpolation=cv2.INTER_CUBIC)\n",
    "        picture = cv2.resize(picture, (w, h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        background = cv2.imread(backgrounds[np.random.randint(0, len(backgrounds))])\n",
    "        shadow = cv2.imread(shadows[np.random.randint(0, len(shadows))], 0)\n",
    "\n",
    "        text_mask = get_mask(text)\n",
    "        seg_mask = get_mask(picture)\n",
    "        syn_pic = syn_picture_text(picture, text, text_mask)\n",
    "        color_weight = np.random.uniform(low=0.7, high=1.0)\n",
    "        ab = np.random.uniform(low=0.3, high=0.8)\n",
    "\n",
    "        syn_tex = syn_texture(\n",
    "            syn_pic,\n",
    "            texture,\n",
    "            text_mask=text_mask,\n",
    "            seg_mask=seg_mask,\n",
    "            alpha=1 - ab,\n",
    "            beta=ab,\n",
    "            color_weight=(color_weight, 1 - color_weight),\n",
    "        )\n",
    "        ratio = np.random.uniform(low=1.00, high=1.01)\n",
    "        syn_back, text_mask, seg_mask, paper_mask = syn_background(\n",
    "            syn_tex, background, text_mask, seg_mask, ratio=ratio\n",
    "        )  # 1.00-1.15\n",
    "\n",
    "        texture = cv2.resize(texture, (w, h), interpolation=cv2.INTER_CUBIC)\n",
    "        texture_flatten = texture.flatten().reshape(h * w, c)\n",
    "        avg_color = get_average_color(texture_flatten)\n",
    "        avg_color = 255 * (1 - ab) + avg_color * ab\n",
    "\n",
    "        for m in range(3):\n",
    "            background_colors[m].append(avg_color[m])\n",
    "\n",
    "        shadow = cv2.resize(shadow, (w, h), interpolation=cv2.INTER_CUBIC)\n",
    "        syn_back = cv2.resize(syn_back, (w, h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        syn_shadowed = syn_shadow(syn_back, shadow, scale=1)\n",
    "        scale = np.random.uniform(low=1.01, high=1.1)\n",
    "        (\n",
    "            trans_img,\n",
    "            trans_shadowed_img,\n",
    "            text_mask,\n",
    "            fig_mask,\n",
    "            paper_mask,\n",
    "        ) = perspective_trans(\n",
    "            syn_back, syn_shadowed, text_mask, seg_mask, paper_mask, scale=scale\n",
    "        )\n",
    "\n",
    "        text_mask = cv2.resize(text_mask, (w, h), interpolation=cv2.INTER_CUBIC)\n",
    "        fig_mask = cv2.resize(fig_mask, (w, h), interpolation=cv2.INTER_CUBIC)\n",
    "        fig_mask = cv2.morphologyEx(\n",
    "            np.where(fig_mask > 0, 1, 0).astype(np.uint8), cv2.MORPH_CLOSE, (10, 10)\n",
    "        )\n",
    "        # paper_mask = cv2.resize(paper_mask, (w, h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        cv2.imwrite(os.path.join(root_path, f\"img/{num}.png\"), trans_shadowed_img)\n",
    "        cv2.imwrite(os.path.join(root_path, f\"gt/{num}.png\"), trans_img)\n",
    "        cv2.imwrite(\n",
    "            os.path.join(root_path, f\"text_mask/{num}.png\"),\n",
    "            (text_mask * 255).astype(np.uint8),\n",
    "        )\n",
    "        cv2.imwrite(\n",
    "            os.path.join(root_path, f\"figure_mask/{num}.png\"),\n",
    "            (fig_mask * 255).astype(np.uint8),\n",
    "        )\n",
    "        # cv2.imwrite(os.path.join(root_path, f\"paper_mask/{num}.png\"), (paper_mask*255).astype(np.uint8))\n",
    "        cv2.imwrite(\n",
    "            os.path.join(root_path, f\"shadow/{num}.png\"), (shadow).astype(np.uint8)\n",
    "        )\n",
    "        cv2.imwrite(\n",
    "            os.path.join(root_path, f\"seg_mask/{num}.png\"),\n",
    "            ((text_mask + fig_mask) * 255).astype(np.uint8),\n",
    "        )\n",
    "        cv2.imwrite(\n",
    "            os.path.join(root_path, f\"avg_color/{num}.png\"),\n",
    "            np.full_like(texture_flatten, avg_color).reshape(h, w, c),\n",
    "        )\n",
    "\n",
    "        img_paths.append(f\"dataset/FSDSRD/img/{num}.png\")\n",
    "        gt_paths.append(f\"dataset/FSDSRD/gt/{num}.png\")\n",
    "        shadow_mask_paths.append(f\"dataset/FSDSRD/shadow/{num}.png\")\n",
    "        text_mask_paths.append(f\"dataset/FSDSRD/text_mask/{num}.png\")\n",
    "        figure_mask_paths.append(f\"dataset/FSDSRD/seg_mask/{num}.png\")\n",
    "\n",
    "        k += 1\n",
    "\n",
    "df[\"img\"] = img_paths\n",
    "df[\"gt\"] = gt_paths\n",
    "df[\"B\"], df[\"G\"], df[\"R\"] = (\n",
    "    background_colors[0],\n",
    "    background_colors[1],\n",
    "    background_colors[2],\n",
    ")\n",
    "df[\"shadow_mask\"] = shadow_mask_paths\n",
    "df[\"text_mask\"] = text_mask_paths\n",
    "df[\"figure_mask\"] = figure_mask_paths\n",
    "\n",
    "df.to_csv(\"../csv/FSDSRD/dataset.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0299aec0d6ab1eecb6cb5c442dac294f52269a9cdac625839481a3060c084ac0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
